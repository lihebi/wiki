#+TITLE: Compiler

This file describe the general concept of a compiler. I'm going to
relearn it in the hard way.


* Parser

Three category of parsers:
- universal :: Cocke–Younger–Kasami algorithm (CYK) and the Earley
               parser. They can parse any grammar, but slow.
- bottom up :: build parse tree from bottom to top
- top down :: build parse tree from top to bottom

There are many different methods of each top-down and bottom-up
parsers. The most efficient top-down and bottom-up methods work only
for subclasses of grammars. Some important subclasses is LL and LR
grammar.

- LL grammar :: often used by hand-implemented parser
- LR grammar :: accept more grammars, but usually construct by tools

Some terms:
- parse tree :: a graphical representation of a derivation that
                filters out the order in which productions are applied
                to replace non-terminals.

Of course, regular expression is a subset of context free grammar.

About how to divide lexer rules and parser rules: use regular
expression.
- Regular expression is most useful for describing structure of
  constructs, such as ID and keywords.
- Grammar is most useful for describing nested structures such as
  parentheses, begin-end, if-then-else.

** Write/Fix the grammar
- Ambiguity ::
- Left Recursion :: Top down parser cannot handle left recursion.
- Left Factoring :: a technique to rewrite production rule to achieve
                    the effect that we wait until enough input has
                    been seen to make decision. It makes grammar more
                    suitable for predictive or top-down parsing.

** Top Down Parsing
- Recusrive descent parsing ::
  - general form of top-down parsing
  - may require backtracking
- Predictive parsing ::
  - a special case of recursive-descent parsing
  - do not require backtracking
  - By look ahead fixed number (usually 1) of tokens
- LL(k) :: A class of grammar, for which we can construct a predictive
           parser by looking k symbols ahead.

The general recursive descent parsing problem is:

#+BEGIN_EXAMPLE cpp
void A() {
  choose an A-production
  for (i = 1 to k) {
    if (xi is nonterminal) call X();
    else if (xi = input symbol) advance_to_next_symbol();
    else error();
  }
}
#+END_EXAMPLE

This is non-deterministic since it begins with choose a production. To
augment backtracking to the algorithm, we need:
- try different productions
- at error, return to the line of choose production
- we need a local variable to store where is the input symbol when
  choosing production.

Left recursive grammar can cause a recursive-descent parser (even the
one with backtracking) into an infinite-loop. Because it try to expand
A without consuming any input.

*** TODO LL(1)
What's the LL?
- L :: Scanning input from Left to right
- L :: producing Leftmost derivation
- 1 :: lookahead 1 symbol

It is rich enough to cover most programming constructs. However,
left-recursive and ambiguous can not.

The parser will construct a predictive parsing table.  To solve LL(1),
we use /non-recursive predictive parsing/.  Do not need recursive call
(really??), because it constructs a parsing table. It is table-driven.

- algorithm 1: construct predictive parsing table
- algorithm 2: table driven predictive parsing

*** Recursive Decent Parser v.s. LR Parser generator
Well, In a word, this is actually important. See what the clang guys say [fn:clang]

#+BEGIN_QUOTE
Clang is the "C Language Family Front-end", which means we intend to
support the most popular members of the C family. We are convinced
that the right parsing technology for this class of languages is a
hand-built recursive-descent parser. Because it is plain C++ code,
recursive descent makes it very easy for new developers to understand
the code, it easily supports ad-hoc rules and other strange hacks
required by C/C++, and makes it straight-forward to implement
excellent diagnostics and error recovery.
#+END_QUOTE

[fn:clang] http://clang.llvm.org/features.html



** Bottom Up Parsing
- shift-reduce parsing :: a general style of bottom-up parsing
- LR grammar :: the largest class of grammars for which shift-reduce
                parsers can be built

The bottom up parsing can think as reducing a string to the start
symbol. At each reduction step, a substring is replaced by a
non-terminal. Thus the key decisions are:
- when to reduce
- what production to apply

*** shift-reduce parsing
Think about a stack holding current string, and the input holding the rest input tokens.
- shift :: move from input to stack
- reduce :: replace a substring at the top of the stack

The conflict here:
- shift/reduce conflict :: don't know to shift or reduce.
- reduce/reduce conflict :: don't know which production rule to use

Grammar that contains these conflicts are non-LR grammar.

*** LR(k) Parsing
- L :: left to right scanning
- R :: producing rightmost derivation
- k :: number of lookahead (when omitted, assume 1)

LR parsers are table driven, like the non-recursive LL parsers.
- LR Grammar :: a grammar for which we can construct a LR parser for it.

Over LL parsing, it is better because:
- LR parsers can be constructed to recognize virtually all programming
  language constructs for which context-free grammars can be written.
- the most general non-backtracking shift-reduce parsing, and can be
  implemented as efficient as others
- can detect syntactic error as soon as it is possible to do so on a
  left-to-right scan of input
- LR grammar is super set of LL grammar

The drawback: hard to construct by hand.

**** Simple LR Parsing (SLR)

- LR(0) Item :: each production rule will be written in a dot format:
                put one dot somewhere in the rule. This will result in
                many items.
- Set of LR(0) Items :: a set of the items
- Canonical LR(0) collection :: a collection of /sets/ of LR(0) Items,
     that is typically used (others are useless).

To construct Canonical LR(0) collection, introduce the CLOSURE and
GOTO functions:
- CLOSURE(I) :: where I is a set of items, if $A \rightarrow \alpha
                \cdot B \beta$ is in CLOSURE(I), and $B \rightarrow
                \gamma$, $B \rightarrow \cdot \gamma$ is in the set.
- GOTO(I,X) :: where I is a set of items, X is a grammar
               symbol. Produce a closure, if $A \rightarrow \alpha
               \cdot X \beta$, $A \rightarrow \alpha X \cdot \beta$ is
               in GOTO(T,X).

Now the algorithm to construct canonical LR(0) items
#+BEGIN_EXAMPLE cpp
void items(G') {
  C=CLOSURE({S->.S'});
  repeat until no new {
    for (each set I in C) {
      for (each grammar symbol X) {
        add GOTO(I,X) to C}}}}
#+END_EXAMPLE

Now we can define LR(0) Automata:
- state :: the canonical LR(0) collection
- transition :: GOTO function

Set up for parsing: Now we have the components:
- input :: the remaining input
- stack :: the stack holds the states. Note that each state
           corresponding to exactly one symbol (yes, but why??). So we
           can always convert to the symbols from states.
- parsing table :: contains two parts: ACTION and GOTO
  - ACTION(i,a) :: state i, next terminal a. The result is
    - shift j :: shift the terminal and go to state j
    - reduce $A \rightarrow \beta$ :: reduce \beta (on the top of stack)
       to A
    - accept ::
    - error ::
  - GOTO(i, A)=j :: map state i and non-terminal A to state j

Parsing algorithm:
- action = shift s :: do it
- action = reduce $A \rightarrow \beta$ :: do the reduction by popping
     out $|\beta|$ states, and then push state GOTO(stack.top, A).

The algorithm can be written as:

#+BEGIN_EXAMPLE cpp
  while (true) {
    s = stack.top;
    a = next input;
    if (ACTION(s,a) = shift t) {
      stack.push(t)
      advance(a)
    } else if (ACTION(s,a) = reduce A to beta) {
      stack.pop(len(beta));
      t = stack.top
      stack.push(GOTO(t,A))
      output production A->beta
    } else if (ACTION=accept | error) {}
  }
#+END_EXAMPLE

Algorithm for construct SLR parsing table:
1. get canonical LR(0) collection
2. ACTION(i,a) = 
  - shift j :: if $A \rightarrow \alpha \cdot a \beta$ is in I_i, and
               GOTO(I_i,a)=I_j
  - reduce A to \alpha :: if $A \rightarrow \alpha \cdot$ in I_i and a
       in FOLLOW(A).
  - accept :: if $S' \rightarrow S \cdot$ is in I_i and a = $

**** LR(1)
So we now allow lookahead. By this we can handle more grammars than
LR(0). There're two methods:
- canonical-LR (LR) :: construct based on LR(1) items, a much larger
     set than LR(0) items. The parsing table is much bigger, so not
     good in practice.
- lookahead-LR (LALR) :: based on LR(0) (??? should be LR(1) here?)
     sets of items, but has many fewer states than LR(1) items. The
     parsing table is no bigger than SLR tables. The modern choice.

* FIRST and FOLLOW
The construction of /both/ top-down and bottom-up parsers needs these
two functions.

- FIRST($\alpha$) :: $\alpha$ is a string of grammar symbols. The set
     of terminals that $\alpha$ can begin with. E.g ~A::=cB~, ~FIRST(A)=c~
- FOLLOW(A) :: non-terminal A, to be the set of terminals that can
               appear immediately to the right of A.


* Error Recovery

- panic-mode :: discard input symbols until /synchronizing tokens/ are
                found. This is typically delimiters, such as semicolon
                or braces.
- phrase-level :: perform local correction, such as remove extra
                  semicolon, replace coma with semicolon. This is not
                  good.
- error-production :: use common errors
- global-correction :: there are some algorithms to choose a minimal
     sequence of changes to obtain a globally least cost
     correction. (What are they??) [Dragon P196]



* Tools
** Elsa and Elkhound
- http://www.scottmcpeak.com/elkhound/

Elkhound is an ancient parser generator, and Elsa is the C++ parser built upon it.
It is clean docs, maybe clean code, worth to check out.

It implements the Generalized LR (GLR) parsing, which works with any context-free grammars.
LR parsers (like bison) requires the grammar to be LALR(1).

- GLR: https://en.wikipedia.org/wiki/GLR_parser


Parsing with arbitrary context-free grammars has two key advantages:
(1) unbounded lookahead, and (2) support for ambiguous grammars. Both
of them are achieved by allowing multiple potential parses to coexist
for as long as necessary.

The downside, since it is more general, is slower performance.

** Semantic Design Inc
A Commercial Parser Front end:
- http://www.semanticdesigns.com/Products/FrontEnds/CppFrontEnd.html
